{"docstore/data": {"40d65862-6fa8-43a3-a613-ee14b6cc8d5f": {"__data__": {"id_": "40d65862-6fa8-43a3-a613-ee14b6cc8d5f", "embedding": null, "metadata": {"tag": "p", "url": "https://app.slack.com/client/T06PYF8R5J7/C079BRFKJJW"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a42fbc3d-fd7f-447d-bbbb-ece54d9c1e06", "node_type": "4", "metadata": {"url": "https://app.slack.com/client/T06PYF8R5J7/C079BRFKJJW"}, "hash": "a1ea7f1592f641d79a2d60fbb40041561e3463ddcd3a73ec35d005d5f235697b", "class_name": "RelatedNodeInfo"}}, "text": "We're quite sorry about this! Before you try to troubleshoot, please do check https://slack-status.com - the problem may be on our end. Here are a few things to try: Check our Help Center for more details, or drop us a line .", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55d0b1ca-4500-44be-bd98-7810c5f3eab0": {"__data__": {"id_": "55d0b1ca-4500-44be-bd98-7810c5f3eab0", "embedding": null, "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02403d4c-f56e-4902-9aca-4e43bbea1666", "node_type": "4", "metadata": {"url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/"}, "hash": "68fdeedb2de19e0306d97aeb690a10c34fd9ea6968a3af227c2f75e2c8ddb860", "class_name": "RelatedNodeInfo"}}, "text": "Document and Node objects are core abstractions within LlamaIndex. A Document is a generic container around any data source - for instance, a PDF, an API output, or retrieved data from a database. They can be constructed manually, or created automatically via our data loaders. By default, a Document stores text along with some other attributes. Some of these are listed below. Note : We have beta support for allowing Documents to store images, and are actively working on improving its multimodal capabilities. A Node represents a \"chunk\" of a source Document, whether that is a text chunk, an image, or other. Similar to Documents, they contain metadata and relationship information with other nodes. Nodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. By default every Node derived from a Document will inherit the same metadata from that Document (e.g. a \"file_name\" filed in the Document is propagated to every Node). Here are some simple snippets to get started with Documents and Nodes. Take a look at our in-depth guides for more details on how to use Documents/Nodes.", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96d00912-8888-4706-9328-f9c50db7860f": {"__data__": {"id_": "96d00912-8888-4706-9328-f9c50db7860f", "embedding": null, "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "192968bc-f96b-4e7f-8c7e-3df9afa07634", "node_type": "4", "metadata": {"url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/"}, "hash": "166c395dbf6140ec6d3b6fbe74e0a895456587cd9139de35bdb7ef2cfa8606f1", "class_name": "RelatedNodeInfo"}}, "text": "Nodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures. Nodes are a first-class citizen in LlamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our NodeParser classes. For instance, you can do You can also choose to construct Node objects manually and skip the first section. For instance, The RelatedNodeInfo class can also store additional metadata if needed: Each node has an node_id property that is automatically generated if not manually specified. This ID can be used for a variety of purposes; this includes being able to update nodes in storage, being able to define relationships between nodes (through IndexNode ), and more. You can also get and set the node_id of any TextNode directly. Hi, how can I help you? \ud83e\udd99", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69a26506-58b6-48a8-b4cc-73be09fd88db": {"__data__": {"id_": "69a26506-58b6-48a8-b4cc-73be09fd88db", "embedding": null, "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/understanding/querying/querying/"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1a0b82dc-1500-4edc-b9d3-a9eef7d969b7", "node_type": "4", "metadata": {"url": "https://docs.llamaindex.ai/en/stable/understanding/querying/querying/"}, "hash": "14697cdd531ba0e0cc5268a8ba37b5d48d4a78647241334805710d7a331a8a63", "class_name": "RelatedNodeInfo"}}, "text": "Now you've loaded your data, built an index, and stored that index for later, you're ready to get to the most significant part of an LLM application: querying. At its simplest, querying is just a prompt call to an LLM: it can be a question and get an answer, or a request for summarization, or a much more complex instruction. More complex querying could involve repeated/chained prompt + LLM calls, or even a reasoning loop across multiple components. The basis of all querying is the QueryEngine . The simplest way to get a QueryEngine is to get your index to create one for you, like this: However, there is more to querying than initially meets the eye. Querying consists of three distinct stages: Tip You can find out about how to attach metadata to documents and nodes . LlamaIndex features a low-level composition API that gives you granular control over your querying. In this example, we customize our retriever to use a different number for top_k and add a post-processing step that requires that the retrieved nodes reach a minimum similarity score to be included. This would give you a lot of data when you have relevant results but potentially no data if you have nothing relevant. You can also add your own retrieval, response synthesis, and overall query logic, by implementing the corresponding interfaces. For a full list of implemented components and the supported configurations, check out our reference docs . Let's go into more detail about customizing each step: There are a huge variety of retrievers that you can learn about in our module guide on retrievers . We support advanced Node filtering and augmentation that can further improve the relevancy of the retrieved Node objects. This can help reduce the time/number of LLM calls/cost or improve response quality. For example: The full list of node postprocessors is documented in the Node Postprocessor Reference . To configure the desired node postprocessors: After a retriever fetches relevant nodes, a BaseSynthesizer synthesizes the final response by combining the information. You can configure it via Right now, we support the following options: You may want to ensure your output is structured. See our Query Engines + Pydantic Outputs to see how to extract a Pydantic object from a query engine class. Also make sure to check out our entire Structured Outputs guide. If you want to design complex query flows, you can compose your own query pipeline across many different modules, from prompts/LLMs/output parsers to retrievers to response synthesizers to your own custom components. Take a look at our Query Pipelines Module Guide for more details.", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3686fe24-e732-4bde-bd15-c89ceb8e45dd": {"__data__": {"id_": "3686fe24-e732-4bde-bd15-c89ceb8e45dd", "embedding": null, "metadata": {"tag": "p", "url": "https://github.com/Vidhi1290/LLM---Detect-AI-Generated-Text"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "453b1eff-965a-495e-ac98-42b131641526", "node_type": "4", "metadata": {"url": "https://github.com/Vidhi1290/LLM---Detect-AI-Generated-Text"}, "hash": "1409b5dc03e945c26ac3bacee2d579b0ba77c9ea48ab199d3baff71ca5f35997", "class_name": "RelatedNodeInfo"}}, "text": "\u00a9 2024 GitHub, Inc. We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Create a list to organize your starred repositories. Name . 32 remaining Description . 160 remaining type to add emoji to the name or description. Couldn't load subscription status. Retry Forks could not be loaded This will remove {{ repoNameWithOwner }} from the {{ listsWithCount }} that it's been added to. AI-Generated Text Detection: A BERT-powered solution for accurately identifying AI-generated text. Seamlessly integrated, highly accurate, and user-friendly.\ud83d\ude80 Welcome to our AI-Generated Text Detection project! In this repository, we present a robust solution for detecting AI-generated text using BERT, a cutting-edge natural language processing model. Whether you're a researcher, developer, or a curious enthusiast, this project empowers you to explore, understand, and combat AI-generated content effectively. AI-generated content is becoming increasingly sophisticated, making it challenging to distinguish between genuine and computer-generated text. Our project aims to tackle this issue by leveraging the power of BERT (Bidirectional Encoder Representations from Transformers) to identify and flag AI-generated text segments. Whether you're dealing with chatbots, articles, or social media posts, our solution offers accurate detection, ensuring the authenticity of digital content. Follow these simple steps to get started with our AI-Generated Text Detection tool: Our solution follows a comprehensive approach to AI-generated text detection: Data Preprocessing: We clean and preprocess the textual data, removing noise and irrelevant information to enhance the accuracy of our model. BERT Tokenization: Leveraging the BERT tokenizer, we encode the preprocessed text, preparing it for input into our detection model. Model Training: Using a BERT-based sequence classification model, we train the system to distinguish between genuine and AI-generated text with a high degree of accuracy. Predictions: Once trained, the model generates predictions for test data, highlighting potential AI-generated content segments. Result Analysis: The results are saved in a CSV file, allowing users to review and analyze the detected segments along with their confidence scores. We welcome contributions from the community! Whether you're a seasoned developer, a data science enthusiast, or a domain expert, your insights and expertise can enhance our project. \ud83d\ude80 Connect With Me: If you find this project interesting or helpful, don't hesitate to follow me for more exciting updates and projects! Let's learn and grow together! \ud83c\udf1f AI-Generated Text Detection: A BERT-powered solution for accurately identifying AI-generated text. Seamlessly integrated, highly accurate, and user-friendly.\ud83d\ude80", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fcd20b0b-bb11-4eab-b088-39619bfe0b66": {"__data__": {"id_": "fcd20b0b-bb11-4eab-b088-39619bfe0b66", "embedding": null, "metadata": {"tag": "p", "url": "https://github.com/kv-22"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "723c0b9f-9a27-4208-a768-bd02f08d9836", "node_type": "4", "metadata": {"url": "https://github.com/kv-22"}, "hash": "e5ebd29fd7cf97c9b7a5a82f91d0345caf1e6228a9e5c65b47686f69c2c736c5", "class_name": "RelatedNodeInfo"}}, "text": "\u00a9 2024 GitHub, Inc. We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . You can @mention other users and organizations to link to them. Prolog Python 1 Jupyter Notebook Forked from GDSC-IAU/Selection-Python Jupyter Notebook Forked from Joud73/Salary-Prediction Jupyter Notebook Java", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "408aaf9f-37d1-4b6a-ab86-754b338ab840": {"__data__": {"id_": "408aaf9f-37d1-4b6a-ab86-754b338ab840", "embedding": null, "metadata": {"tag": "p", "url": "https://github.com/kv-22/chatWithHistory"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "649e0827-7493-4458-ac40-aa98f60dabd2", "node_type": "4", "metadata": {"url": "https://github.com/kv-22/chatWithHistory"}, "hash": "4102971b6fbbc03e17730d67e93a022d49088b758c20488ae79f90b7b689fdd2", "class_name": "RelatedNodeInfo"}}, "text": "\u00a9 2024 GitHub, Inc. We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Create a list to organize your starred repositories. Name . 32 remaining Description . 160 remaining type to add emoji to the name or description. Couldn't load subscription status. Retry Forks could not be loaded This will remove {{ repoNameWithOwner }} from the {{ listsWithCount }} that it's been added to.", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1bd5bff-66a3-4b5b-a9ab-8856c84ff4e3": {"__data__": {"id_": "d1bd5bff-66a3-4b5b-a9ab-8856c84ff4e3", "embedding": null, "metadata": {"tag": "p", "url": "https://github.com/predlico/ARAGOG"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b9fce6c1-7ef9-4662-a5cc-61835db841ab", "node_type": "4", "metadata": {"url": "https://github.com/predlico/ARAGOG"}, "hash": "73c4f8ec117dd01bd30a0b568bffa32604845dbd5ff3b78442807389bd3bcc8a", "class_name": "RelatedNodeInfo"}}, "text": "\u00a9 2024 GitHub, Inc. We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Create a list to organize your starred repositories. Name . 32 remaining Description . 160 remaining type to add emoji to the name or description. Couldn't load subscription status. Retry Forks could not be loaded This will remove {{ repoNameWithOwner }} from the {{ listsWithCount }} that it's been added to. ARAGOG- Advanced RAG Output Grading. Exploring and comparing various Retrieval-Augmented Generation (RAG) techniques on AI research papers dataset. Includes modular code for easy experimentation and reusability. This repository contains the code, data, and analysis for our study [link later] on advanced Retrieval-Augmented Generation (RAG) techniques. It's part of our scientific paper investigating the efficacy of various RAG techniques in enhancing the precision and contextual relevance of LLMs. To replicate our experiments or to analyze our results, please ensure to fill in the necessary API keys and other configurations by creating a .env file (see .sample.env ) - the .env is ignored in .gitignore for security. Setup the python environment using either venv or pyenv or your favourite python environment amanger. Call the environment aragog or anything you like. Then run pip install -r requirements.txt to install all necessary dependencies. The res_analysis.ipynb notebook provides a detailed examination of the experimental results stored in final_results.xlsx . To set up vector databases for experiments, run the vector_db.py script. Subsequently, execute main.py to perform the experiments. Post-experimentation, use res_analysis.ipynb for analyzing the results. Helper functions in utils.py are employed across scripts to streamline processes. Contributions are welcome. For any changes or enhancements, please open an issue first to discuss what you would like to change. This project is open-source and available under the MIT License . ARAGOG- Advanced RAG Output Grading. Exploring and comparing various Retrieval-Augmented Generation (RAG) techniques on AI research papers dataset. Includes modular code for easy experimentation and reusability.", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa482ad6-f094-4e89-8918-2e2ee6b54674": {"__data__": {"id_": "aa482ad6-f094-4e89-8918-2e2ee6b54674", "embedding": null, "metadata": {"tag": "p", "url": "https://github.com/run-llama/llama_index/issues/3928"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "352cdc6f-698e-4a50-9c53-ba007d6b9e8e", "node_type": "4", "metadata": {"url": "https://github.com/run-llama/llama_index/issues/3928"}, "hash": "193ad052c8fe9333e386f4036d597ddaeae0b488d85d5ba24f80ee9b0cf8c23e", "class_name": "RelatedNodeInfo"}}, "text": "\u00a9 2024 GitHub, Inc. We read every piece of feedback, and take your input very seriously. To see all available qualifiers, see our documentation . Sorry, something went wrong. In a google drive folder I have 7 docs for which I have created the vector store index using GoogleDriveReader = download_loader('GoogleDriveReader') folder_id = '1LFa04mF3U300ttoej-EkWcT35sHHDZJL' loader = GoogleDriveReader() documents = loader.load_data(folder_id=folder_id) index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context ) Now in the same folder i have added some more documents , how I can update the index how can I use index.insert(document) how it will identify new documents only whether it will create index from scratch or it will append new index into that previously created files. please provide the details about this The text was updated successfully, but these errors were encountered: Sorry, something went wrong. I am currently working on the same problem, but i got the feeling the GPTVectorStoreIndex does not support updating or at least not inserting new documents. I also tryed the add and insert methods which are both do not exsist for the GPTVectorStoreIndex. Maybe we need to use another vector index... the documentation is not clear about that, so let me know if you find a solution. Here is my code WHICH DOES NOT WORK: AttributeError: 'GPTVectorStoreIndex' object has no attribute 'merge' AttributeError: 'GPTVectorStoreIndex' object has no attribute 'insert_documents' AttributeError: 'GPTVectorStoreIndex' object has no attribute 'add_documents'. Did you mean: 'from_documents'? Kind regards Update: Ive read somewhere setting overwrite=false should have this effect, however this also did not work. The index is overwritten... index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context, overwrite=False) Sorry, something went wrong. Sorry, something went wrong. I would love to have this feature added please. Sorry, something went wrong. Sorry, something went wrong. It already works actually So i check if the index exists (for example by checking if there are files... if not i create a new one, after saving it to disc i move the documents into another folder. If it exists i add the new documents to it and then move them into another folder after the index is updated. You can do this by adding new nodes to an existing index :) I hope this helps! So the magic happens with index.insert_nodes(new_nodes) Sorry, something went wrong. Sorry, something went wrong. Hey @j0schi , how did you check if there are files for index_exists variable ? Sorry, something went wrong. Sorry, something went wrong. Hi, this is probably not the best solution but it works for me :) You might have to change the folder / path according to your system. Sorry, something went wrong. Sorry, something went wrong. Thanks for your response! Actually I'm planning to use a vector store from those : https://gpt-index.readthedocs.io/en/latest/how_to/storage/customization.html#vector-store-integrations-and-storage instead of persist_dir Edit : I don't think that we can do that through llama_index, so I'll just use the library of the vector store Sorry, something went wrong. Sorry, something went wrong. Hey @j0schi , I don't know why but this code is not updating anything even code is almost same as yours. Sorry, something went wrong. Sorry, something went wrong. Take a look at http://localhost:8000/how_to/index/document_management.html , especially the refresh section! Sorry, something went wrong. Sorry, something went wrong. Its local server link can't check this? Sorry, something went wrong. Sorry, something went wrong. Its local server link can't check this? https://gpt-index.readthedocs.io/en/latest/how_to/index/document_management.html Sorry, something went wrong. Sorry, something went wrong. Have similar qustion : Do I need to persist my index again after inserting new data into my VectorStore Index or it it done automatically ? I am using MilvusVectorStore. My method : Sorry, something went wrong. Sorry, something went wrong. Have similar qustion : Do I need to persist my index again after inserting new data into my VectorStore Index or it it done automatically ? I am using MilvusVectorStore. My method : Based on my experience with FaissVectorStore , one doesn't have to persist and load the index again to make these newly added nodes available to the query. Sorry, something went wrong. Add your comment here... We don\u2019t support that file type. Try again with GIF, JPEG, JPG, MOV, MP4, PNG, SVG, WEBM, CPUPROFILE, CSV, DMP, DOCX, FODG, FODP, FODS, FODT, GZ, JSON, JSONC, LOG, MD, ODF, ODG, ODP, ODS, ODT, PATCH, PDF, PPTX, TGZ, TXT, XLS, XLSX or ZIP. Attaching documents requires write permission to this repository. Try again with GIF, JPEG, JPG, MOV, MP4, PNG, SVG, WEBM, CPUPROFILE, CSV, DMP, DOCX, FODG, FODP, FODS, FODT, GZ, JSON, JSONC, LOG, MD, ODF, ODG, ODP, ODS, ODT, PATCH, PDF, PPTX, TGZ, TXT, XLS, XLSX or ZIP. This file is empty. Try again with a file that\u2019s not empty. This file is hidden. Try again with another file. Something went really wrong, and we can\u2019t process that file. Try again. Nothing to preview No branches or pull requests Sorry, something went wrong and we weren't able to fetch your subscription status. Retry", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55a1e43b-7f23-41d5-a6f9-c11dfeb1feab": {"__data__": {"id_": "55a1e43b-7f23-41d5-a6f9-c11dfeb1feab", "embedding": null, "metadata": {"tag": "p", "url": "https://tasty.co/recipe/the-best-chewy-chocolate-chip-cookies"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "14d2125b-921c-40d4-b28b-ba05c7bf751f", "node_type": "4", "metadata": {"url": "https://tasty.co/recipe/the-best-chewy-chocolate-chip-cookies"}, "hash": "f3f5a01b9e845ff0f65ac813f8b800690bdb661b957286ad148165d5da271f03", "class_name": "RelatedNodeInfo"}}, "text": "Have a recipe of your own to share? Submit your recipe There are a few crucial steps to baking the chewiest, tastiest chocolate chip cookies. First, skip using chips and opt for chunks. Second, instead of using just one type of chocolate (like semisweet), use a mix of semisweet, milk, and dark chocolate. Third, take the time to allow the cookie dough to rest overnight in the refrigerator. Yes, we know it's a pain, but doing so will yield a cookie with a more complex flavor and delicious toffee notes. Lastly, use an ice cream scoop to portion the cookie dough onto the baking sheet. This will produce even-sized cookies every single time. Follow these simple steps, and you'll be rewarded with a cookie that's crisp and chewy on the outside and gooey on the inside! 1 hr 5 min 1 hr 5 min 20 minutes 20 min 15 minutes 15 min Inspired by buzzfeed.com 1 hr 5 min 1 hr 5 min 20 minutes 20 min 15 minutes 15 min for 12 cookies Estimated values based on one serving size. Build your cart with Tasty, then choose how you want to get your order from Walmart. I love this recipe so much!! I am NEVER using chocolate chips ever again! These cookies are decadent, chewy, and oh so delicious! I used light brown sugar and salted butter. I highly recommend this recipe to any chocolate chip cookie lover! if the cookies get hard, store them in and airtight bag or container with a slice of bread and they will become soft again soon I have made these about 4 times now! My tip is to not melt the butter until it\u2019s completely liquid, then whisk it until the soft butter is incorporated with the fully melted butter before adding. Also if you let the dough rest in the fridge for 3 hours or more, they get nice and toffee-like. The cookies were so delicious \ud83d\ude0b They were a little bigger than expected. I put the cookies on a nonstick pan instead of parchment paper and they still turned out fine. \ud83d\ude0d They were really easy to make. I\u2019m 12 \ud83d\ude02 100% I\u2019d make again! I bake them for 5 minutes less to avoid over cooking as they\u2019re cooling. This ensures they will still be soft after even a week of storage (if they last that long). I\u2019ve made this recipe twice now and I changed the recipe a tad bit. I added 1/4 cup more flour, 1/2 teaspoon of salt and I used 3/4 cup of nestle\u2019s dark chocolate chips . I let them hang out in the fridge for about 2 hours. I also preheated my oven to 375 and let them bake for 10 mins and took them out to sit about 5 min to finish. Be sure to get the right kind of chocolate! Not chocolate chips. Get the chunks! Trust me, it makes a difference. When I was incorporating the melted butter and sugars, it doesn\u2019t look the same like the one in the video. I continued the recipe but it ended up looking like cake batter, so I added 1/4 cup of flour and it turned out great! I recommend mixing chocolate chips and chocolate chunks for my diversity Use half melted butter and half soften butter that\u2019s makes a chewier cookie Way too sweet, use less sugar These cookies are LEGIT the best cookies i\u2019ve ever made! Have made them several times and they come out great every time. I use a bit less brown sugar and a bit more white sugar so the cookie will spread. Really good! Inspired by buzzfeed.com", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cf57d14a-892d-4873-a238-1c4ab0905ca3": {"__data__": {"id_": "cf57d14a-892d-4873-a238-1c4ab0905ca3", "embedding": null, "metadata": {"tag": "p", "url": "https://www.allrecipes.com/recipe/10813/best-chocolate-chip-cookies/"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6bcd8151-49be-4dd9-8c37-32c7f44c266a", "node_type": "4", "metadata": {"url": "https://www.allrecipes.com/recipe/10813/best-chocolate-chip-cookies/"}, "hash": "7247577abb1b872af32b896b6e4a4bde75a919ffadaa39a6fc668a82a6924c12", "class_name": "RelatedNodeInfo"}}, "text": "This chocolate chip cookie recipe makes delicious cookies with crisp edges and chewy middles. This chocolate chip cookie recipe is truly the best. Just take it from the 14,000 members of the Allrecipes community who have given it rave reviews! These chocolate chip cookies are beloved because they're soft, chewy, and absolutely irresistible. Our top-rated recipe for chocolate chip cookies will quickly become your go-to. Making bakery-worthy chocolate chip cookies is much easier than it seems. You'll find a detailed ingredient list and step-by-step instructions in the recipe below, but let's go over the basics: These are the kitchen staples you'll need to make the best chocolate chip cookies of your life: Here's a very brief overview of what you can expect when you make chocolate chip cookies from-scratch: In an oven preheated to 350 degrees F, the chocolate chip cookies should be perfectly baked in about 10 minutes. The edges should be golden brown and the cookies should be mostly set (they'll continue to set as the cool). Allrecipes Video \u201cEveryone needs a good chocolate chip cookie recipe,\u201d says culinary producer Nicole McLaughlin (a.k.a. NicoleMcMom ). Here are a few of her expert tips and tricks for making perfect chocolate chip cookies every time: Store the cooled chocolate chip cookies in an airtight container at room temperature for up to a week. If you want to go the extra mile, throw a piece of white bread into the container \u2014 it'll absorb the dry air and keep the cookies soft for longer. Learn more : How to Store Cookies So They Stay Fresh Yes! You can freeze baked chocolate chip cookies and chocolate chip cookie dough. Learn more : How to Freeze Cookies and Cookie Dough for Easy Baking \"This has been my go-to chocolate chip cookie recipe since I found it on Allrecipes several years ago,\" says GCKJA . \"The recipe is not the 'back of the bag' recipe, with different ratios of all ingredients and that's what makes these cookies so darned good!\" \"By far my favorite chocolate chip cookie recipe,\" raves Sonja Ellingson . \"Exactly the way I like them. Chewy, crispy and thin. I added some toffee chips in the second batch and they were over the top good!\" \"My go-to recipe,\" says Andrea Howard . \"I sometimes add oatmeal, nuts, raisins, etc. but they are also fantastic without. Crunchy and chewy in every bite!\" 1 cup butter, softened 1 cup white sugar 1 cup packed brown sugar 2 eggs 2 teaspoons vanilla extract 1 teaspoon baking soda 2 teaspoons hot water \u00bd teaspoon salt 3 cups all-purpose flour 2 cups semisweet chocolate chips 1 cup chopped walnuts Gather your ingredients, making sure your butter is softened, and your eggs are room temperature. Dotdash Meredith Food Studios Preheat the oven to 350 degrees F (175 degrees C). Beat butter, white sugar, and brown sugar with an electric mixer in a large bowl until smooth. Dotdash Meredith Food Studios Beat in eggs, one at a time, then stir in vanilla. Dotdash Meredith Food Studios Dissolve baking soda in hot water. Add to batter along with salt. Dotdash Meredith Food Studios Stir in flour, chocolate chips, and walnuts. Dotdash Meredith Food Studios Drop spoonfuls of dough 2 inches apart onto ungreased baking sheets. Dotdash Meredith Food Studios Bake in the preheated oven until edges are nicely browned, about 10 minutes. Dotdash Meredith Food Studios Cool on the baking sheets briefly before removing to a wire rack to cool completely. Dotdash Meredith Food Studios Store in an airtight container or serve immediately and enjoy! Dotdash Meredith Food Studio * Percent Daily Values are based on a 2,000 calorie diet. Your daily values may be higher or lower depending on your calorie needs. ** Nutrient information is not available for all ingredients. Amount is based on available nutrient data. (-) Information is not currently available for this nutrient. If you are following a medically restrictive diet, please consult your doctor or registered dietitian before preparing this recipe for personal consumption. Powered by the ESHA Research Database \u00a9 2018, ESHA Research, Inc. All Rights Reserved", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c990aa29-4d35-401e-9da8-4f43ef0cf9ac": {"__data__": {"id_": "c990aa29-4d35-401e-9da8-4f43ef0cf9ac", "embedding": null, "metadata": {"tag": "p", "url": "https://www.bettycrocker.com/recipes/ultimate-chocolate-chip-cookies/77c14e03-d8b0-4844-846d-f19304f61c57"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "42a5ee4b-c085-4d14-bdac-71cfd8dcee1f", "node_type": "4", "metadata": {"url": "https://www.bettycrocker.com/recipes/ultimate-chocolate-chip-cookies/77c14e03-d8b0-4844-846d-f19304f61c57"}, "hash": "e6f584d17cb92b707b0a26d1f12aa005ac04901dbeca1513599c1f1a0b83a4cf", "class_name": "RelatedNodeInfo"}}, "text": "We can almost guarantee you won\u2019t have leftovers\u2014this is the best chocolate chip cookie recipe around! If you do end up with any extra chocolate chip cookies, they can easily be stored for later enjoyment. To keep your leftover cookies chewy and soft, store them at room temperature in resealable food-storage plastic bags or stacked in tightly covered containers. If you want to freeze your homemade chocolate chip cookies instead, wait until they\u2019ve cooled completely. Stack them in between layers of wax paper in a covered freezer container or plastic freezer bag and freeze your cookies for up to 2 months. To thaw, keep them covered at room temperature for 1 to 2 hours. Go ahead and chow down! Want to switch it up? This chocolate chip cookie recipe can easily be customized with endless flavor combinations! Just replace the chocolate chips and nuts with the same amount of the new ingredients you want to add. Try adding macadamia nuts and white vanilla baking chips, or pack a double punch of peanut flavor with peanut butter chips and chopped peanuts. Make salted butterscotch-pecan cookies by swapping in butterscotch chips and chopped pecans, and then sprinkling your cookies with coarse salt before baking. We also have plenty of other chocolate chip cookie recipes to try. Can\u2019t decide between cookies and brownies? Our Double Chocolate Chip Cookies , are packed full of decadent chocolate flavor. Our Oatmeal Chocolate Chip Cookies , offer next-level deliciousness, too\u2014you really can never go wrong with a classic! Baking is a science, and we can prove it! Whether you prefer a soft, chewy chocolate chip cookie or a crisp, crunchy cookie, consider the factors that make a difference in cookie structure\u2014from the ratio and type of sugars used to the amount of butter or shortening used, and how much flour is stirred in. If you like your cookies slightly crispy on the outside and chewy on the inside\u2014what many people consider the perfect texture for a chocolate chip cookie\u2014just follow this recipe exactly! Our Ultimate Chocolate Chip Cookies are truly the best chocolate chip cookies around\u2014they\u2019re called \u201cultimate\u201d for a reason. Prefer your homemade chocolate chip cookies crispy and thin? Cut out the brown sugar completely, and increase the amount of granulated sugar to 1 1/2 cups. Granulated sugar contains less moisture and helps cookies spread as they bake. After taking your chocolate chip cookies out of the oven, let them cool on a cookie sheet for five minutes. The cookies will keep baking, allowing them to crisp up further as the moisture evaporates. If you want your chocolate chip cookies airy, soft and cakey, we\u2019ve got you covered. Add in an extra egg for additional moisture and structure, and add in 2 tablespoons of milk with the egg to help soften the dough as it bakes and give the cookie a cake-like crumb. Increase the amount of flour to 3 cups to help the cookies rise (rather than spread). The perfectly cakey chocolate chip cookie is just a few steps away! Want to have a crowd-favorite cookie always at the ready? Follow this chocolate chip cookie recipe to get the perfect dough, and freeze it for later baking! Freeze individual unbaked dough balls on cookie sheets. Once the dough balls are frozen, place them in plastic freezer bags and freeze them for up to 2 months. When you\u2019re ready to bake your cookies, take the frozen cookie dough balls from the freezer and place them on a cookie sheet. Let them sit at room temperature for 15 minutes as you preheat the oven. Keep an eye on your chocolate chip cookies as they bake\u2014the bake time might need to be adjusted slightly. This hack guarantees delicious cookies in a snap!", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5036859f-b51f-44d2-9944-5270f09498d9": {"__data__": {"id_": "5036859f-b51f-44d2-9944-5270f09498d9", "embedding": null, "metadata": {"tag": "p", "url": "https://www.ibm.com/topics/machine-learning"}, "excluded_embed_metadata_keys": ["urls"], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "871040ba-7b17-4310-9f97-3173a50e117a", "node_type": "4", "metadata": {"url": "https://www.ibm.com/topics/machine-learning"}, "hash": "4e16241a77e260154e0b93e75342b7081fe0b9c441eaa5ea24f17bc6287a43ed", "class_name": "RelatedNodeInfo"}}, "text": "Machine learning (ML) is a branch of artificial intelligence (AI) and computer science that focuses on the using data and algorithms to enable AI to imitate the way that humans learn, gradually improving its accuracy. UC Berkeley (link resides outside ibm.com) breaks out the learning system of a machine learning algorithm into three main parts. Explore the benefits of generative AI and ML and learn how to confidently incorporate these technologies into your business. Register for the white paper on AI governance Since deep learning and machine learning tend to be used interchangeably, it\u2019s worth noting the nuances between the two. Machine learning, deep learning, and neural networks are all sub-fields of artificial intelligence. However, neural networks is actually a sub-field of machine learning, and deep learning is a sub-field of neural networks. The way in which deep learning and machine learning differ is in how each algorithm learns. \"Deep\" machine learning can use labeled datasets, also known as supervised learning, to inform its algorithm, but it doesn\u2019t necessarily require a labeled dataset. The deep learning process can ingest unstructured data in its raw form (e.g., text or images), and it can automatically determine the set of features which distinguish different categories of data from one another. This eliminates some of the human intervention required and enables the use of large amounts of data. You can think of deep learning as \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides outside ibm.com). Classical, or \"non-deep,\" machine learning is more dependent on human intervention to learn. Human experts determine the set of features to understand the differences between data inputs, usually requiring more structured data to learn. Neural networks, or artificial neural networks (ANNs), are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network by that node. The \u201cdeep\u201d in deep learning is just referring to the number of layers in a neural network. A neural network that consists of more than three layers\u2014which would be inclusive of the input and the output\u2014can be considered a deep learning algorithm or a deep neural network. A neural network that only has three layers is just a basic neural network. Deep learning and neural networks are credited with accelerating progress in areas such as computer vision, natural language processing, and speech recognition. See the blog post \u201c AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What\u2019s the Difference? \u201d for a closer look at how the different concepts relate. Explore the watsonx.ai interactive demo Download \"Machine learning for Dummies\" Explore Gen AI for developers Machine learning models fall into three primary categories. Supervised learning , also known as supervised machine learning, is defined by its use of labeled datasets to train algorithms to classify data or predict outcomes accurately. As input data is fed into the model, the model adjusts its weights until it has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting . Supervised learning helps organizations solve a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox. Some methods used in supervised learning include neural networks, na\u00efve bayes, linear regression, logistic regression, random forest, and support vector machine (SVM). Unsupervised learning , also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). These algorithms discover hidden patterns or data groupings without the need for human intervention. This method\u2019s ability to discover similarities and differences in information make it ideal for exploratory data analysis, cross-selling strategies, customer segmentation, and image and pattern recognition. It\u2019s also used to reduce the number of features in a model through the process of dimensionality reduction. Principal component analysis (PCA) and singular value decomposition (SVD) are two common approaches for this. Other algorithms used in unsupervised learning include neural networks, k-means clustering, and probabilistic clustering methods. Semi-supervised learning offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of not having enough labeled data for a supervised learning algorithm. It also helps if it\u2019s too costly to label enough data. For a deep dive into the differences between these approaches, check out \" Supervised vs. Unsupervised Learning: What's the Difference? \" Reinforcement machine learning is a machine learning model that is similar to supervised learning, but the algorithm isn\u2019t trained using sample data. This model learns as it goes by using trial and error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem. The IBM Watson\u00ae system that won the Jeopardy! challenge in 2011 is a good example. The system used reinforcement learning to learn when to attempt an answer (or question, as it were), which square to select on the board, and how much to wager\u2014especially on daily doubles. Learn more about reinforcement learning A number of machine learning algorithms are commonly used. These include: Depending on your budget, need for speed and precision required, each algorithm type \u2014supervised, unsupervised, semi-supervised, or reinforcement\u2014has its own advantages and disadvantages. For example, decision tree algorithms are used for both predicting numerical values (regression problems) and classifying data into categories. Decision trees use a branching sequence of linked decisions that may be represented with a tree diagram. A prime advantage of decision trees is that they are easier to validate and audit than a neural network. The bad news is that they can be more unstable than other decision predictors. Overall, there are many advantages to machine learning that businesses can leverage for new efficiencies. These include machine learning identifying patterns and trends in massive volumes of data that humans might not spot at all. And this analysis requires little human intervention: just feed in the dataset of interest and let the machine learning system assemble and refine its own algorithms\u2014which will continually improve with more data input over time. Customers and users can enjoy a more personalized experience as the model learns more with every experience with that person. On the downside, machine learning requires large training datasets that are accurate and unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering sufficient data and having a system robust enough to run it might also be a drain on resources. Machine learning can also be prone to error, depending on the input. With too small a sample, the system could produce a perfectly logical algorithm that is completely wrong or misleading. To avoid wasting budget or displeasing customers, organizations should act on the answers only when there is high confidence in the output. Here are just a few examples of machine learning you might encounter every day: Speech recognition: It is also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, and it is a capability which uses natural language processing (NLP) to translate human speech into a written format. Many mobile devices incorporate speech recognition into their systems to conduct voice search\u2014e.g. Siri\u2014or improve accessibility for texting. Customer service: Online chatbots are replacing human agents along the customer journey, changing the way we think about customer engagement across websites and social media platforms. Chatbots answer frequently asked questions (FAQs) about topics such as shipping, or provide personalized advice, cross-selling products or suggesting sizes for users. Examples include virtual agents on e-commerce sites; messaging bots, using Slack and Facebook Messenger; and tasks usually done by virtual assistants and voice assistants. Computer vision: This AI technology enables computers to derive meaningful information from digital images, videos, and other visual inputs, and then take the appropriate action. Powered by convolutional neural networks, computer vision has applications in photo tagging on social media, radiology imaging in healthcare, and self-driving cars in the automotive industry. Recommendation engines: Using past consumption behavior data, AI algorithms can help to discover data trends that can be used to develop more effective cross-selling strategies. Recommendation engines are used by online retailers to make relevant product recommendations to customers during the checkout process. Robotic process automation (RPA ): Also known as software robotics, RPA uses intelligent automation technologies to perform repetitive manual tasks. Automated stock trading: Designed to optimize stock portfolios, AI-driven high-frequency trading platforms make thousands or even millions of trades per day without human intervention. Fraud detection: Banks and other financial institutions can use machine learning to spot suspicious transactions. Supervised learning can train a model using information about known fraudulent transactions. Anomaly detection can identify transactions that look atypical and deserve further investigation. As machine learning technology has developed, it has certainly made our lives easier. However, implementing machine learning in businesses has also raised a number of ethical concerns about AI technologies. Some of these include: While this topic garners a lot of public attention, many researchers are not concerned with the idea of AI surpassing human intelligence in the near future. Technological singularity is also referred to as strong AI or superintelligence. Philosopher Nick Bostrum defines superintelligence as \u201cany intellect that vastly outperforms the best human brains in practically every field, including scientific creativity, general wisdom, and social skills.\u201d Despite the fact that superintelligence is not imminent in society, the idea of it raises some interesting questions as we consider the use of autonomous systems, like self-driving cars. It\u2019s unrealistic to think that a driverless car would never have an accident, but who is responsible and liable under those circumstances? Should we still develop autonomous vehicles, or do we limit this technology to semi-autonomous vehicles which help people drive safely? The jury is still out on this, but these are the types of ethical debates that are occurring as new, innovative AI technology develops. While a lot of public perception of artificial intelligence centers around job losses, this concern should probably be reframed. With every disruptive, new technology, we see that the market demand for specific job roles shifts. For example, when we look at the automotive industry, many manufacturers, like GM, are shifting to focus on electric vehicle production to align with green initiatives. The energy industry isn\u2019t going away, but the source of energy is shifting from a fuel economy to an electric one. In a similar way, artificial intelligence will shift the demand for jobs to other areas. There will need to be individuals to help manage AI systems. There will still need to be people to address more complex problems within the industries that are most likely to be affected by job demand shifts, such as customer service. The biggest challenge with artificial intelligence and its effect on the job market will be helping people to transition to new roles that are in demand. Privacy tends to be discussed in the context of data privacy, data protection, and data security. These concerns have allowed policymakers to make more strides in recent years. For example, in 2016, GDPR legislation was created to protect the personal data of people in the European Union and European Economic Area, giving individuals more control of their data. In the United States, individual states are developing policies, such as the California Consumer Privacy Act (CCPA), which was introduced in 2018 and requires businesses to inform consumers about the collection of their data. Legislation such as this has forced companies to rethink how they store and use personally identifiable information (PII). As a result, investments in security have become an increasing priority for businesses as they seek to eliminate any vulnerabilities and opportunities for surveillance, hacking, and cyberattacks. Instances of bias and discrimination across a number of machine learning systems have raised many ethical questions regarding the use of artificial intelligence. How can we safeguard against bias and discrimination when the training data itself may be generated by biased human processes? While companies typically have good intentions for their automation efforts, Reuters (link resides outside ibm.com) highlights some of the unforeseen consequences of incorporating AI into hiring practices. In their effort to automate and simplify a process, Amazon unintentionally discriminated against job candidates by gender for technical roles, and the company ultimately had to scrap the project. Harvard Business Review (link resides outside ibm.com) has raised other pointed questions about the use of AI in hiring practices, such as what data you should be able to use when evaluating a candidate for a role. Bias and discrimination aren\u2019t limited to the human resources function either; they can be found in a number of applications from facial recognition software to social media algorithms. As businesses become more aware of the risks with AI, they\u2019ve also become more active in this discussion around AI ethics and values. For example, IBM has sunset its general purpose facial recognition and analysis products. IBM CEO Arvind Krishna wrote: \u201cIBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values and Principles of Trust and Transparency.\u201d Since there isn\u2019t significant legislation to regulate AI practices, there is no real enforcement mechanism to ensure that ethical AI is practiced. The current incentives for companies to be ethical are the negative repercussions of an unethical AI system on the bottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration between ethicists and researchers to govern the construction and distribution of AI models within society. However, at the moment, these only serve to guide. Some research (link resides outside ibm.com) shows that the combination of distributed responsibility and a lack of foresight into potential consequences aren\u2019t conducive to preventing harm to society. Read more about IBM's position on AI Ethics Selecting a platform can be a challenging process, as the wrong system can drive up costs, or limit the use of other valuable tools or technologies. When reviewing multiple vendors to select an AI platform, there is often a tendency to think that more features = a better system. Maybe so, but reviewers should start by thinking through what the AI platform will be doing for their organization. What machine learning capabilities need to be delivered and what features are important to accomplish them? One missing feature might doom the usefulness of an entire system. Here are some features to consider. Reimagine how you work with AI: our diverse, global team of more than 20,000 AI experts can help you quickly and confidently design and scale AI and automation across your business, working across our own IBM watsonx technology and an open ecosystem of partners to deliver any AI model, on any cloud, guided by ethics and trust. Operationalize AI across your business to deliver benefits quickly and ethically. Our rich portfolio of business-grade AI products and analytics solutions are designed to reduce the hurdles of AI adoption and establish the right data foundation while optimizing for outcomes and responsible use. Multiply the power of AI with our next-generation AI and data platform. IBM watsonx is a portfolio of business-ready tools, applications and solutions, designed to reduce the costs and hurdles of AI adoption while optimizing outcomes and responsible use of AI. Granite is IBM\u2019s flagship series of LLM foundation models based on decoder-only transformer architecture. Granite language models are trained on trusted enterprise data spanning internet, academic, code, legal and finance. Learn the fundamental concepts for AI and generative AI, including prompt engineering, large language models and the best open source projects. AI technology has been rapidly evolving over the last couple of decades. Learn how businesses are implementing AI today. Learn tools businesses use to efficiently run and manage AI models and empower their data scientist with technology that can help optimize their data-driven decision making. Explore how machine learning projects help you continually learn from data and predict the future. Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data.", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"40d65862-6fa8-43a3-a613-ee14b6cc8d5f": {"doc_hash": "b5edc5d2d2e02abb3b96a9e1d1536ebfdb0a96f1018f6bc096a7139da695f255", "ref_doc_id": "a42fbc3d-fd7f-447d-bbbb-ece54d9c1e06"}, "55d0b1ca-4500-44be-bd98-7810c5f3eab0": {"doc_hash": "7b54cea52cebf8b4fe6f136364518fff51b7d07f7252c3935c506e789dd262da", "ref_doc_id": "02403d4c-f56e-4902-9aca-4e43bbea1666"}, "96d00912-8888-4706-9328-f9c50db7860f": {"doc_hash": "da400fd5dbb0c2350a5904e51b811ee2b7eb8df917d926f9ff056fd902594273", "ref_doc_id": "192968bc-f96b-4e7f-8c7e-3df9afa07634"}, "69a26506-58b6-48a8-b4cc-73be09fd88db": {"doc_hash": "62f0593769d8af7f30897ab04188ae24dc2cefc08b11a73cbfea56782eef1ef2", "ref_doc_id": "1a0b82dc-1500-4edc-b9d3-a9eef7d969b7"}, "3686fe24-e732-4bde-bd15-c89ceb8e45dd": {"doc_hash": "aac9da820c9c85ee55f914763289e49d90bc13a2d56ecaa469e15c47c1a70026", "ref_doc_id": "453b1eff-965a-495e-ac98-42b131641526"}, "fcd20b0b-bb11-4eab-b088-39619bfe0b66": {"doc_hash": "86cd8389c628b8ef6a7f2e8969ea82a4209f1727bfbc4503a01052b461e4ae77", "ref_doc_id": "723c0b9f-9a27-4208-a768-bd02f08d9836"}, "408aaf9f-37d1-4b6a-ab86-754b338ab840": {"doc_hash": "557038f03e02850a929733e846cfa938e70afa7f48c80a8ddd99faf5d21663e4", "ref_doc_id": "649e0827-7493-4458-ac40-aa98f60dabd2"}, "d1bd5bff-66a3-4b5b-a9ab-8856c84ff4e3": {"doc_hash": "9c0601c5a0cb3c862f260def313fe9818e2205e14e1b7a5df388d44b625cca2a", "ref_doc_id": "b9fce6c1-7ef9-4662-a5cc-61835db841ab"}, "aa482ad6-f094-4e89-8918-2e2ee6b54674": {"doc_hash": "92f6bc97992584440afadd79e8f5de092012550366cbbbac83c905435544eeaf", "ref_doc_id": "352cdc6f-698e-4a50-9c53-ba007d6b9e8e"}, "55a1e43b-7f23-41d5-a6f9-c11dfeb1feab": {"doc_hash": "6c21093c23f8c5ffca7eeac6af2c255bcaa109b9464dc42bf62504561bb26590", "ref_doc_id": "14d2125b-921c-40d4-b28b-ba05c7bf751f"}, "cf57d14a-892d-4873-a238-1c4ab0905ca3": {"doc_hash": "d5dfea505379c497c349581ecb782839b7edaa4e87bbf47bdc70fc023b7081a5", "ref_doc_id": "6bcd8151-49be-4dd9-8c37-32c7f44c266a"}, "c990aa29-4d35-401e-9da8-4f43ef0cf9ac": {"doc_hash": "642f352df5efb490689db512d7bc7e19b44edddc020cf15e2fcadfac7818c37a", "ref_doc_id": "42a5ee4b-c085-4d14-bdac-71cfd8dcee1f"}, "5036859f-b51f-44d2-9944-5270f09498d9": {"doc_hash": "f24d4dc60b04614218bb34c4a4e4361cb6d9712d1ea43ce43e35e40b354a4d83", "ref_doc_id": "871040ba-7b17-4310-9f97-3173a50e117a"}}, "docstore/ref_doc_info": {"a42fbc3d-fd7f-447d-bbbb-ece54d9c1e06": {"node_ids": ["40d65862-6fa8-43a3-a613-ee14b6cc8d5f"], "metadata": {"tag": "p", "url": "https://app.slack.com/client/T06PYF8R5J7/C079BRFKJJW"}}, "02403d4c-f56e-4902-9aca-4e43bbea1666": {"node_ids": ["55d0b1ca-4500-44be-bd98-7810c5f3eab0"], "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/"}}, "192968bc-f96b-4e7f-8c7e-3df9afa07634": {"node_ids": ["96d00912-8888-4706-9328-f9c50db7860f"], "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_nodes/"}}, "1a0b82dc-1500-4edc-b9d3-a9eef7d969b7": {"node_ids": ["69a26506-58b6-48a8-b4cc-73be09fd88db"], "metadata": {"tag": "p", "url": "https://docs.llamaindex.ai/en/stable/understanding/querying/querying/"}}, "453b1eff-965a-495e-ac98-42b131641526": {"node_ids": ["3686fe24-e732-4bde-bd15-c89ceb8e45dd"], "metadata": {"tag": "p", "url": "https://github.com/Vidhi1290/LLM---Detect-AI-Generated-Text"}}, "723c0b9f-9a27-4208-a768-bd02f08d9836": {"node_ids": ["fcd20b0b-bb11-4eab-b088-39619bfe0b66"], "metadata": {"tag": "p", "url": "https://github.com/kv-22"}}, "649e0827-7493-4458-ac40-aa98f60dabd2": {"node_ids": ["408aaf9f-37d1-4b6a-ab86-754b338ab840"], "metadata": {"tag": "p", "url": "https://github.com/kv-22/chatWithHistory"}}, "b9fce6c1-7ef9-4662-a5cc-61835db841ab": {"node_ids": ["d1bd5bff-66a3-4b5b-a9ab-8856c84ff4e3"], "metadata": {"tag": "p", "url": "https://github.com/predlico/ARAGOG"}}, "352cdc6f-698e-4a50-9c53-ba007d6b9e8e": {"node_ids": ["aa482ad6-f094-4e89-8918-2e2ee6b54674"], "metadata": {"tag": "p", "url": "https://github.com/run-llama/llama_index/issues/3928"}}, "14d2125b-921c-40d4-b28b-ba05c7bf751f": {"node_ids": ["55a1e43b-7f23-41d5-a6f9-c11dfeb1feab"], "metadata": {"tag": "p", "url": "https://tasty.co/recipe/the-best-chewy-chocolate-chip-cookies"}}, "6bcd8151-49be-4dd9-8c37-32c7f44c266a": {"node_ids": ["cf57d14a-892d-4873-a238-1c4ab0905ca3"], "metadata": {"tag": "p", "url": "https://www.allrecipes.com/recipe/10813/best-chocolate-chip-cookies/"}}, "42a5ee4b-c085-4d14-bdac-71cfd8dcee1f": {"node_ids": ["c990aa29-4d35-401e-9da8-4f43ef0cf9ac"], "metadata": {"tag": "p", "url": "https://www.bettycrocker.com/recipes/ultimate-chocolate-chip-cookies/77c14e03-d8b0-4844-846d-f19304f61c57"}}, "871040ba-7b17-4310-9f97-3173a50e117a": {"node_ids": ["5036859f-b51f-44d2-9944-5270f09498d9"], "metadata": {"tag": "p", "url": "https://www.ibm.com/topics/machine-learning"}}}}